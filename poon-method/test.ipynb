{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlosito/Documents/vsCode/vs-DANI/DL-Project/V-WSD/poon-method/new-env/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from transformers import VisionEncoderDecoderModel, ViTFeatureExtractor, AutoTokenizer\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from rouge import Rouge\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('bank.n.01') sloping land (especially the slope beside a body of water)\n",
      "Synset('depository_financial_institution.n.01') a financial institution that accepts deposits and channels the money into lending activities\n",
      "Synset('bank.n.03') a long ridge or pile\n",
      "Synset('bank.n.04') an arrangement of similar objects in a row or in tiers\n",
      "Synset('bank.n.05') a supply or stock held in reserve for future use (especially in emergencies)\n",
      "Synset('bank.n.06') the funds held by a gambling house or the dealer in some gambling games\n",
      "Synset('bank.n.07') a slope in the turn of a road or track; the outside is higher than the inside in order to reduce the effects of centrifugal force\n",
      "Synset('savings_bank.n.02') a container (usually with a slot in the top) for keeping money at home\n",
      "Synset('bank.n.09') a building in which the business of banking transacted\n",
      "Synset('bank.n.10') a flight maneuver; aircraft tips laterally about its longitudinal axis (especially in turning)\n",
      "Synset('bank.v.01') tip laterally\n",
      "Synset('bank.v.02') enclose with a bank\n",
      "Synset('bank.v.03') do business with a bank or keep an account at a bank\n",
      "Synset('bank.v.04') act as the banker in a game or in gambling\n",
      "Synset('bank.v.05') be in the banking business\n",
      "Synset('deposit.v.02') put into a bank account\n",
      "Synset('bank.v.07') cover with ashes so to control the rate of burning\n",
      "Synset('trust.v.01') have confidence or faith in\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.wsd import lesk\n",
    "for ss in wn.synsets('bank'):\n",
    "    print(ss, ss.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'image-description.json'\n",
    "if os.path.exists(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        dictionary = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class_3(test_data, dictionary):\n",
    "  generated_text_dict = dictionary\n",
    "  generated_text_list = []\n",
    "  global selected_col\n",
    "  for img in range(1,11):\n",
    "      selected_col = test_data[f'img{img}']\n",
    "\n",
    "      \n",
    "      if selected_col in generated_text_dict.keys():\n",
    "        pred = generated_text_dict[selected_col]\n",
    "        generated_text_list.append(pred)\n",
    "      \n",
    "      else:\n",
    "        IMAGE_PATH = \"/Users/carlosito/Documents/vsCode/vs-DANI/DL-Project/semeval-2023-task-1-V-WSD-train-v1/trial_v1/trial_images_v1/\"\n",
    "        IMAGE_PATH_EACH = IMAGE_PATH + selected_col\n",
    "        \n",
    "        plot_img = Image.open(IMAGE_PATH_EACH)\n",
    "        if plot_img.mode != \"RGB\":          #add this thing\n",
    "          plot_img = plot_img.convert(mode=\"RGB\")\n",
    "          \n",
    "          \n",
    "        pixel_values = feature_extractor(images= plot_img, return_tensors=\"pt\").pixel_values\n",
    "        pixel_values = pixel_values.to(device)\n",
    "        gen_kwargs = {\"max_length\": max_length, \"num_beams\": num_beams}\n",
    "        output_ids = model.generate(pixel_values, **gen_kwargs)\n",
    "        pred = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
    "        \n",
    "        generated_text_dict[selected_col] = pred[0]\n",
    "        generated_text_list.extend(pred)\n",
    "\n",
    "  try:    \n",
    "    word_description = lesk(word_tokenize(test_data['context']), test_data['keyword']).definition()\n",
    "\n",
    "  except:\n",
    "    new_reference_word = np.setdiff1d(test_data['context'].split(), test_data['keyword'].split())[0]\n",
    "    word_description = lesk(word_tokenize(test_data['context']), new_reference_word)\n",
    "    if word_description is None:\n",
    "      output = 'No image'\n",
    "      return output\n",
    "      \n",
    "    else:\n",
    "      word_description = word_description.definition()\n",
    "  \n",
    "\n",
    "  rouge_score_list = []\n",
    "  for i in range(10):\n",
    "      rouge_score = rouge.get_scores(word_description, generated_text_list[i] )[0]['rouge-1']['p']\n",
    "      rouge_score_list.append(rouge_score)\n",
    "      \n",
    "\n",
    "  predicted_image_idx = np.argmax(rouge_score_list)\n",
    "  output = test_data[f'img{predicted_image_idx+1}']\n",
    "\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/Users/carlosito/Documents/vsCode/vs-DANI/DL-Project/semeval-2023-task-1-V-WSD-train-v1/trial_v1/\"\n",
    "data = pd.read_csv(PATH+'trial.data.v1.txt', delimiter='\\t', header=None)\n",
    "keys = pd.read_csv(PATH+'trial.gold.v1.txt', delimiter='\\t', header=None)\n",
    "df = pd.concat([data, keys],axis=1)\n",
    "df.columns = ['keyword', 'context', 'img1', 'img2', 'img3', 'img4', 'img5', 'img6', 'img7', 'img8', 'img9', 'img10', 'gold_key']\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "\n",
    "max_length = 16\n",
    "num_beams = 4\n",
    "gen_kwargs = {\"max_length\": max_length, \"num_beams\": num_beams}\n",
    "\n",
    "rouge = Rouge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = df.iloc[3]\n",
    "generated_text_list = []\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(nrows = 5, ncols = 2, figsize = (10,20))\n",
    "\n",
    "for img in range(1,11):\n",
    "    selected_col = test_data[f'img{img}']\n",
    "    IMAGE_PATH = \"/Users/carlosito/Documents/vsCode/vs-DANI/DL-Project/semeval-2023-task-1-V-WSD-train-v1/trial_v1/trial_images_v1/\"\n",
    "    IMAGE_PATH_EACH = IMAGE_PATH + selected_col\n",
    "    \n",
    "    plot_img = Image.open(IMAGE_PATH_EACH)\n",
    "    axes.flatten()[img-1].imshow(plot_img)\n",
    "    \n",
    "    \n",
    "    pixel_values = feature_extractor(images= plot_img, return_tensors=\"pt\").pixel_values\n",
    "    pixel_values = pixel_values.to(device)\n",
    "    gen_kwargs = {\"max_length\": max_length, \"num_beams\": num_beams}\n",
    "    output_ids = model.generate(pixel_values, **gen_kwargs)\n",
    "    pred = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
    "    axes.flatten()[img-1].title.set_text(pred[0])\n",
    "\n",
    "    generated_text_list.extend(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_description = lesk(word_tokenize(test_data['context']), test_data['keyword']).definition()\n",
    "print(word_description)\n",
    "rouge_score_list = []\n",
    "for i in range(10):\n",
    "    rouge_score = rouge.get_scores(word_description, generated_text_list[i] )[0]['rouge-1']['f']\n",
    "    print(rouge_score)\n",
    "    rouge_score_list.append(rouge_score)\n",
    "    \n",
    "print()\n",
    "predicted_image_idx = np.argmax(rouge_score_list)\n",
    "print(predicted_image_idx)\n",
    "\n",
    "print(f\"predicted img: {test_data[f'img{predicted_image_idx+1}']}\")\n",
    "print(f\"true img: {test_data.gold_key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list = []\n",
    "for ind in tqdm(df.index):\n",
    "    result = predict_class_3(test_data = df.loc[ind], dictionary= dictionary)\n",
    "    result_list.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['predicted_img'] = result_list\n",
    "np.sum(df.gold_key == df.predicted_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('new-env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b67112068909551cfea70082520a0ef75e5d3e570f99842861d4e2cef8049ea6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
