{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "XPx1ENMtMrXj"
      },
      "outputs": [],
      "source": [
        "NAME = \"Aung\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNfiEbwop-5o",
        "outputId": "c13ac979-91ba-4d82-d542-3af44060f06b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QgQ9pLUxRt_g"
      },
      "outputs": [],
      "source": [
        "%pip install transformers\n",
        "%pip install sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "_ZCY-CQ1Rt_h"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "Image.MAX_IMAGE_PIXELS = None\n",
        "\n",
        "import torch\n",
        "from transformers import VisionEncoderDecoderModel, ViTFeatureExtractor, AutoTokenizer\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import os\n",
        "import io\n",
        "import glob\n",
        "import zipfile\n",
        "import tarfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "gN88OTxfRt_k"
      },
      "outputs": [],
      "source": [
        "PATH = \"/content/drive/MyDrive/SemEval_Data/SplitData/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "5mX1_42ERt_l",
        "outputId": "e8309660-e04d-4254-c15f-3f2cdfa724c3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-7a2d0d47-f28b-4ff5-9224-3835a60dd221\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>image.4841.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>image.5419.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>image.2263.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>image.436.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>image.1032.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a2d0d47-f28b-4ff5-9224-3835a60dd221')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7a2d0d47-f28b-4ff5-9224-3835a60dd221 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7a2d0d47-f28b-4ff5-9224-3835a60dd221');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       image_name\n",
              "0  image.4841.jpg\n",
              "1  image.5419.jpg\n",
              "2  image.2263.jpg\n",
              "3   image.436.jpg\n",
              "4  image.1032.jpg"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.read_csv(PATH+f'unique_image_list_for_{NAME}.csv')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "we2ikpXpHt5A"
      },
      "source": [
        "## Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "Ppe0qENMRt_n"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "9chN5gNJRt_n"
      },
      "outputs": [],
      "source": [
        "max_length = 16\n",
        "num_beams = 4\n",
        "gen_kwargs = {\"max_length\": max_length, \"num_beams\": num_beams}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3t-jYimtRt_o"
      },
      "source": [
        "#### Generate the description for the image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_N3FJ1GIofF",
        "outputId": "3eacda0c-29c5-484b-e1c8-1733bfab15c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['image.4841.jpg',\n",
              " 'image.5419.jpg',\n",
              " 'image.2263.jpg',\n",
              " 'image.436.jpg',\n",
              " 'image.1032.jpg']"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "zipFile = zipfile.ZipFile(\"/content/drive/MyDrive/semeval-2023-task-1-V-WSD-train-v1.zip\")\n",
        "IMG_PATH = \"semeval-2023-task-1-V-WSD-train-v1\"\n",
        "img_list = [item[0] for item in data.values.tolist()]\n",
        "img_list[0:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "kwqUASzsRt_o"
      },
      "outputs": [],
      "source": [
        "def get_images_description(image_path, image_names):\n",
        "    images = list()\n",
        "    for img in image_names:\n",
        "        image = Image.open(io.BytesIO(zipFile.read(image_path + img)))\n",
        "\n",
        "        if image.mode != \"RGB\":\n",
        "            image = image.convert(\"RGB\")\n",
        "        \n",
        "        images.append(image)\n",
        "    \n",
        "    model = VisionEncoderDecoderModel.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
        "    model.to(device)\n",
        "    feature_extractor = ViTFeatureExtractor.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
        "    \n",
        "    pixel_values = feature_extractor(images=images, return_tensors=\"pt\").pixel_values\n",
        "    pixel_values = pixel_values.to(device)\n",
        "\n",
        "    output_ids = model.generate(pixel_values, **gen_kwargs)\n",
        "\n",
        "    preds = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
        "    preds = [pred.strip() for pred in preds]\n",
        "\n",
        "    del pixel_values\n",
        "    del output_ids\n",
        "    del model\n",
        "    \n",
        "    torch.cuda.empty_cache()\n",
        "    \n",
        "    return preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "bVWlW5W3MSSI"
      },
      "outputs": [],
      "source": [
        "description_path = \"/content/drive/MyDrive/SemEval_Data/Descriptions\"\n",
        "if not os.path.exists(description_path):\n",
        "  os.makedirs(description_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSV_ijSHRt_q",
        "outputId": "7e6b934e-81de-4f51-8ced-bf591f8e71fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Working on Data[0:10]\n",
            "Working on Data[10:20]\n",
            "Working on Data[20:30]\n",
            "Working on Data[30:40]\n",
            "Working on Data[40:50]\n"
          ]
        }
      ],
      "source": [
        "batch_size = 10\n",
        "start = 0\n",
        "end = 10\n",
        "descriptions = list()\n",
        "\n",
        "for i in range(round(len(img_list)/batch_size)):\n",
        "  print(f\"Working on Data[{start}:{end}]\")\n",
        "  image_names = img_list[start:end]\n",
        "  desc = get_images_description(\"semeval-2023-task-1-V-WSD-train-v1/train_v1/train_images_v1/\", image_names)\n",
        "  descriptions.extend(desc)\n",
        "  start += 10\n",
        "  end += 10\n",
        "df = pd.DataFrame({\"image\": img_list, \"description\": descriptions})\n",
        "df.to_csv(description_path+f\"description_for_{NAME}.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Calculate Cosine Scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JAifYuxWO68q"
      },
      "outputs": [],
      "source": [
        "result_path = \"/content/drive/MyDrive/SemEval_Data/Results\"\n",
        "if not os.path.exists(description_path):\n",
        "  os.makedirs(description_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjaVNM5CNf5R"
      },
      "outputs": [],
      "source": [
        "descriptions = pd.read_csv(description_path+f\"description_for_{NAME}.csv\")\n",
        "descriptions.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "buakoPX7NmTB"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(PATH+f\"data_split_for_{NAME}.csv\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QGtjGX1mPIJJ"
      },
      "outputs": [],
      "source": [
        "result = pd.DataFrame(columns=['img_1', 'img_2', 'img_3', 'img_4', 'img_5', 'img_6', 'img_7', 'img_8', 'img_9', 'img_10', 'label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yDcQnr6TNs79"
      },
      "outputs": [],
      "source": [
        "sentence_model =  SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
        "\n",
        "for idx, row in data.iterrows():\n",
        "    embeddings_1 = sentence_model.encode(row['context'], convert_to_tensor=True)\n",
        "    scores = list()\n",
        "    for i in range(1, 11):\n",
        "        desc = descriptions[descriptions['image'] == row[f'img_{i}']]['description'].values[0]\n",
        "        embeddings_2 = sentence_model.encode(desc, convert_to_tensor=True)\n",
        "        cosine_scores = util.pytorch_cos_sim(embeddings_1, embeddings_2).item()\n",
        "        \n",
        "        scores.append(cosine_scores)\n",
        "        result.loc[idx, f'img_{i}'] = cosine_scores\n",
        "\n",
        "        del embeddings_2\n",
        "    result.loc[idx, 'label'] = row[f\"img_{np.argmax(scores) + 1}\"]\n",
        "    del embeddings_1\n",
        "result.to_csv(result_path+f\"similarities_and_prediction_for_{NAME}.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fo8EORVUNw_X"
      },
      "outputs": [],
      "source": [
        "accuracy_score(data['gold_key'], result['label'])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.0 ('Torch')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "861422ce924561d14451c158b4f671c78a8ad5148ef4e5f0393ebe2641d92b66"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
